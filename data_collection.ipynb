{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4675a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9429e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3ec7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36'}\n",
    "    r = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(r.content,'html.parser')\n",
    "    return soup,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49149262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anime_details(soup):\n",
    "    details = {}\n",
    "    details['name'] = soup.find(class_='title-name').text\n",
    "    details['description'] = soup.find(itemprop='description').text\n",
    "    details['score']=soup.find(itemprop='ratingValue').text\n",
    "    info_list = [i.text.replace('\\n','').replace(' ','') for i in \n",
    "                 soup.find(class_='leftside').find_all(class_='spaceit_pad')]\n",
    "\n",
    "    cols = ['Type', 'Episodes','Premiered','Studios', 'Source', \n",
    "            'Rating','Members', 'Favorites']\n",
    "\n",
    "    for col in cols:\n",
    "        details[col.lower()] = next((element.split(':')[-1] for element \n",
    "                             in info_list if col in element),None)\n",
    "    try:\n",
    "        genres = [i[:len(i)//2] for i in next((element.split(':')[-1] for element \n",
    "                                 in info_list if 'Genres' in element),None).split(',')]\n",
    "        for i in range(len(genres)):\n",
    "            details[f'genre-{i+1}'] = genres[i]\n",
    "    except:\n",
    "        genre = next((element.split(':')[-1] for element \n",
    "                                 in info_list if 'Genre' in element),None)\n",
    "        details['genre-1'] = genre[:len(genre)//2]\n",
    "\n",
    "    return pd.DataFrame(details,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2586e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_detail(review_soup):\n",
    "    details = {}\n",
    "    details['username'] = review_soup.find(class_='username').text.replace('\\n','')\n",
    "    details['anime_name'] = review_soup.find(class_='title').text\n",
    "    details['anime_link'] = review_soup.find(class_='title')['href']\n",
    "    details['recommended'] = review_soup.find(class_='tag').text\n",
    "    details['rating_user'] = review_soup.find(class_='rating').find(class_='num').text\n",
    "    return pd.DataFrame(details,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab892852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "url = f'https://myanimelist.net/reviews.php?t=anime&filter_check=&filter_hide=2&preliminary=off&spoiler=on&p={page}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages=723\n",
    "offset=1\n",
    "for page in range(offset,pages+offset):\n",
    "    print(f'currently on page {page}')\n",
    "    soup,_ = get_soup(url)\n",
    "    all_reviews = soup.find_all(class_='review-element js-review-element')\n",
    "    for review in all_reviews:\n",
    "        df = pd.concat([df,get_review_detail(review)],ignore_index=True)\n",
    "df.to_csv(f'data/review_{offset}-{offset+pages-1}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cc5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/review_1-722.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b9d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_links = df['anime_link'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85f6a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for anime_link in anime_links:\n",
    "    soup,_ = get_soup(anime_link)\n",
    "    df = pd.concat([df,get_anime_details(soup)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37aa6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/anime-details.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapidAnime",
   "language": "python",
   "name": "rapidanime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
